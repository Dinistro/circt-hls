#!/usr/bin/env python3
import argparse
import sys
import os
import subprocess
import shutil
import multiprocessing
import json
from dataclasses import dataclass
from graphviz import Digraph

## CMake configured paths to the tools that we'll be using
CIRCT_BIN_DIR = "@CIRCT_INCLUDE_DIR@/../bin/"
CIRCT_HLS_BIN_DIR = "@CIRCT_HLS_BINARY_DIR@/bin/"
CIRCT_HLS_SOURCE_DIR = "@CIRCT_HLS_SOURCE_DIR@"
LLVM_BIN_DIR = "@LLVM_BINARY_DIR@/bin"
POLYGEIST_BIN_DIR = "@POLYGEIST_BINARY_DIR@"

## Global variables used to drive the tool
# Current mode
mode = None
# Tool arguments
args = None

# =============================================================================
# Print utilities
# =============================================================================


def print_header(text, width=80):
  if args.silent:
    return
  sideWidth = (width - len(text)) // 2 - 2
  print("=" * sideWidth + f" {text} " + "=" * sideWidth)


def print_prefixed(prefix, text):
  if args.silent:
    return
  print(f"{prefix}: {text}")


def print_info(text):
  print_prefixed("INFO", "    " + text)


def print_error(text):
  print_prefixed("ERROR", text)
  sys.exit(1)


def print_step(text):
  print_prefixed("\nSTEP", text)


def copyToCurrentDir(file, filename=None):
  hadFileName = filename is not None
  if filename is None:
    filename = os.path.basename(file)
  shutil.copy(file, filename)
  print_info("Copied '" + file + "' to current directory" +
             f" as {filename}" if hadFileName else "")


# =============================================================================
# Utilities for driving external tools
# =============================================================================


def copyAllowSame(src, dst):
  if os.path.exists(dst):
    if os.path.samefile(src, dst):
      print_info(f"File {dst} already exists, skipping copy...")
      return
  shutil.copy(src, dst)


def runIfNotExists(file, func):
  if not args.rebuild and os.path.exists(file):
    print_info(f"File {file} already exists, skipping...")
    return
  func()


def isFile(file):
  # if file is a file and has an extension
  return os.path.isfile(file) and os.path.splitext(file)[1] != ""


def splitAtEveryNCharacters(string, n):
  return "\\n".join([string[i:i + n] for i in range(0, len(string), n)])


class FileGraph:
  # This is a class for visualizing the different files generated by the tool
  # and the calls between them.
  def __init__(self, outdir):
    self.graph = Digraph("HLSTool Graph",
                         filename=os.path.join(outdir, "hlstool.dot"))
    self.graph.save()

  def add_relation(self, edgeStr, candidateInputs, candidateOutputs=None):
    # Filter candidate inputs based on which of them are actual files
    inputs = [node for node in candidateInputs if node and isFile(node)]
    # Filter candidate outputs based on which of them are actual files
    outputs = [node for node in candidateOutputs if node and isFile(node)]

    # Add edges between the inputs and outputs
    for input in inputs:
      for output in outputs:
        self.graph.edge(input,
                        output,
                        label=splitAtEveryNCharacters(edgeStr, 40))

    self.graph.save()


fileGraph = None


@dataclass
class RunResult:
  returnCode: int
  stdOut: str
  stdErr: str


def run_tool(args,
             stdOutFile=None,
             shell=False,
             liveOutput=False,
             exitOnError=True):
  cmd = " ".join(args)

  infostr = f"Running: {cmd}"
  if stdOutFile:
    infostr += f" > {stdOutFile}"
  print_info(infostr)

  # Register any possible I/O file relations with the file graph
  fileGraph.add_relation(cmd, args, [stdOutFile])

  def onError(returnCode, stdOut, stdErr):
    stdErr = str(stdErr).replace("\\n", "\n")
    print_error(
        f"Error while executing: {cmd}\nstdout:\n{stdOut}\nstderr:\n{stdErr}\n (code: {returnCode})"
    )

  try:
    if shell:
      proc = subprocess.Popen(cmd,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE,
                              shell=True)
      if liveOutput:
        # Continuously poll the process and forward any stdout
        while not proc.poll():
          stdoutdata = proc.stdout.readline()
          if stdoutdata:
            sys.stdout.write(stdoutdata.decode("utf-8"))
          else:
            code = proc.returncode
            break
          stdOut, stdErr = b'', b''
      else:
        stdOut, stdErr = proc.communicate()
        code = proc.returncode
    else:
      res = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
      code = res.returncode
      stdOut, stdErr = res.stdout, res.stderr

    stdOut = stdOut.decode("utf-8")
    stdErr = stdErr.decode("utf-8")

    if code:
      if exitOnError:
        onError(code, stdOut, stdErr)
      else:
        # Just forward the stdout, stderr and exit code to the caller
        return RunResult(code, stdOut, stdErr)

    if stdOutFile:
      with open(stdOutFile, 'w') as f:
        f.write(stdOut)
  except subprocess.CalledProcessError as e:
    onError(e.returncode, "<<subprocess CALLED PROCESS ERROR>>", e.output)


def run_fud(fromType, toType, inputFile, outputFile):
  if fromType == "" or toType == "":
    print_error("Error: Missing fromType or toType")
  run_tool([
      "fud", "exec", "--from", fromType, "--to", toType, "-o", outputFile,
      inputFile
  ])


def run_opt_tool(tool_dir, tool_name, args, inputFile=None, outputFile=None):
  args = [os.path.join(tool_dir, tool_name), *args]
  if inputFile:
    args.append(inputFile)
  run_tool(args, outputFile, shell=True)


def run_polygeist_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(POLYGEIST_BIN_DIR, "polygeist-opt", args, inputFile, outputFile)


def run_circt_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(CIRCT_BIN_DIR, "circt-opt", args, inputFile, outputFile)


def run_hls_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(CIRCT_HLS_BIN_DIR, "hls-opt", args, inputFile, outputFile)


def run_mlir_opt(args, inputFile, outputFile=None):
  run_opt_tool(LLVM_BIN_DIR, "mlir-opt", args, inputFile, outputFile)


class HLSMode:

  def __init__(self, name):
    self.name = name

  def add_arguments(self, subparser):
    raise NotImplementedError("implement me in a subclass")

  def parse_arguments(self, parser):
    raise NotImplementedError("implement me in a subclass")

  def gen_names(self):
    # Generates all possible output file names which we'll reference during the run.
    # Kernel files
    self.kernel_sv = os.path.join(args.outdir, args.kernel_name + ".sv")
    self.dotfile = os.path.join(args.outdir, args.kernel_name + ".dot")
    self.kernel_wrapper = os.path.join(args.outdir, args.kernel_name + ".cpp")

    # Testbench files
    self.tb_poly = os.path.join(args.outdir, args.kernel_name + "_poly.mlir")
    self.tb_poly_flat = os.path.join(args.outdir,
                                     args.kernel_name + "_poly_flat.mlir")
    self.tb_mlir = os.path.join(args.outdir, args.kernel_name + "_tb.mlir")
    self.tb_llvm = os.path.join(args.outdir, args.kernel_name + "_tb_llvm.mlir")
    self.tb_output = os.path.join(args.outdir,
                                  args.kernel_name + "_tb_output.txt")
    self.cosim_call = os.path.join(args.outdir,
                                   args.kernel_name + "_tb_cosim_call.mlir")
    self.cosim_compare = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_compare.mlir")
    self.cosim_lowered = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_lowered.mlir")
    self.cosim_resolved = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_resolved.mlir")

    # Analysis files
    self.resource_estimate = os.path.join(
        args.outdir, args.kernel_name + "_resource_estimate.txt")

    # Mode-specific names
    self.gen_names_mode()

  def run(self):
    # Generate output file names used during the run.
    self.gen_names()

    # Top level runner. Non-mode specific run jobs
    # ...

    # Run mode specific jobs
    self.run_mode()

    # Run post-mode specific jobs
    if args.synth:
      self.run_synth()

    print_header("Finished!")

  def run_synth(self):
    print_step("Running Vivado resource estimation")

    # Copy .tcl and .xdc files to current directory
    copyToCurrentDir(
        os.path.join(CIRCT_HLS_SOURCE_DIR, "tools", "hlstool", "synth.tcl"))
    copyToCurrentDir(
        os.path.join(CIRCT_HLS_SOURCE_DIR, "tools", "hlstool", "device.xdc"))

    # Generate run commands
    vivado_args = ["vivado", "-mode", "batch", "-source", "synth.tcl"]
    # synth arguments (see synth.tcl)
    vivado_args.append("-tclargs")
    vivado_args.append(args.kernel_name)  # top level
    vivado_args.append("xczu3eg-sbva484-1-e")  # part
    vivado_args.append("vivado")  # outdir
    vivado_args.append("1")  # do routing

    print_info("Running Vivado with command: " + " ".join(vivado_args))
    run_tool(vivado_args, shell=True, liveOutput=not args.silent)


class DynamicMode(HLSMode):

  def __init__(self):
    super().__init__('dynamic')

  def add_arguments(self, subparser):
    dynamic_parser = subparser.add_parser('dynamic', help='Dynamic mode')
    dynamic_parser.add_argument('--run_sim',
                                action='store_true',
                                help='Run the HLT testbench.')

    dynamic_parser.add_argument(
        '-e',
        '--genexec',
        type=str,
        help="Generate a HLT testbench which compiles to an executable file. "
        "This is useful if you don\'t want to run the HLT wrapper via. the "
        "mlir-cpu-runner, but instead want an executable file that you can debug"
        " with regular C++ tools")

    dynamic_parser.add_argument(
        '--print_dot',
        help="Prints a dot file of the "
        "handshake circuit",
        action='store_true',
    )
    dynamic_parser.add_argument('--lower',
                                action='store_true',
                                help="Lower the C code to hardware.")
    dynamic_parser.add_argument(
        '--build_sim',
        action='store_true',
        help="Lower the C code to hardware, build the simulator.")
    dynamic_parser.add_argument(
        '--build_tb',
        action='store_true',
        help=
        "Lower the testbench to MLIR, asyncify it (for HLT use), convert to LLVM IR."
    )
    dynamic_parser.add_argument(
        '--hsdbg',
        action='store_true',
        help="Run HSDbg on the circuit. This"
        " assumes that a simulation has been run prior to this.")

    dynamic_parser.add_argument('--hsdbg_port',
                                type=int,
                                default=8080,
                                help="Port to run HSDbg server on.")

    dynamic_parser.add_argument(
        '--hs_kernel',
        action='store_true',
        help="The kernel is a handshake kernel. If this is set, will skip "
        "polygaist and standard to handshake lowering.")

    dynamic_parser.add_argument(
        '--buffer_strategy',
        type=str,
        default="cycles",
        help="Buffer strategy to use, see 'circt-opt --handshake-insert-buffers'"
    )

    dynamic_parser.add_argument(
        '--buffer_size',
        type=int,
        default=2,
        help=
        "Number of slots in each buffer, see 'circt-opt --handshake-insert-buffers'"
    )

  def parse_arguments(self, parser):
    if not args.vcd:
      # Infer a default location for the VCD file based on how HLT emits it.
      args.vcd = os.path.join(args.outdir, 'logs/vlt_dump.vcd')

    if args.hsdbg:
      # Always run print_dot
      args.print_dot |= True

      # If we are running HSDbg there must be simulation results available
      if not os.path.exists(args.vcd):
        parser.error(f"Expected a simulation result file at {args.vcd}. "
                     " Please run a simulation first.")

    if not args.build_sim and not args.lower and not args.run_sim and not \
      args.build_tb and not args.synth and not args.hsdbg:
      # If no specific end-point has been set, we'll stop at building the sim
      # and kernel, but not running the sim.
      print_info("enabling --build_sim due to no specific end-point set")
      args.build_sim |= True
      if args.tb_file:
        print_info("enabling --build_tb due to no specific end-point set")
        args.build_tb |= True

    if args.synth:
      args.lower |= True
      print_info("enabling --lower required by --synth")

    if args.run_sim:
      # Running the sim requires building the sim
      args.build_sim |= True
      args.build_tb |= True
      print_info("enabling --build_sim required by --run_sim")
      print_info("enabling --build_tb required by --run_sim")

    if args.build_sim:
      # Building the sim requires lowering the kernel.
      args.lower |= True
      print_info("enabling --lower required by --build_sim")

  def genPrefixedOutputFileName(self, suffix):
    return os.path.join(args.outdir, args.kernel_name + "_" + suffix)

  def gen_names_mode(self):
    # Generate dynamic-mode specific names.

    # Kernel files
    self.kernel_affine = self.genPrefixedOutputFileName("affine.mlir")
    self.kernel_std = self.genPrefixedOutputFileName("std.mlir")
    self.kernel_std_mem2reg = self.genPrefixedOutputFileName("std_mem2reg.mlir")
    self.kernel_std_pushedconstants = self.genPrefixedOutputFileName(
        "std_pushedconstants.mlir")
    self.kernel_std_flat = self.genPrefixedOutputFileName("std_flat.mlir")
    # A renamed version of the kernel wherein the function name does not clash with
    # the name of the handshake kernel.
    self.kernel_std_ref = self.genPrefixedOutputFileName("std_ref.mlir")
    self.kernel_name_ref = args.kernel_name + "_ref"

    self.kernel_std_max = self.genPrefixedOutputFileName("std_max.mlir")
    self.kernel_handshake = self.genPrefixedOutputFileName("handshake.mlir")
    self.kernel_handshake_buffered = self.genPrefixedOutputFileName(
        "handshake_buffered.mlir")
    self.kernel_handshake_unbuffered = self.genPrefixedOutputFileName(
        "handshake_unbuffered.mlir")
    self.kernel_firrtl = self.genPrefixedOutputFileName("firrtl.mlir")

  def run_mode(self):
    # First, generate all of the names that we'll reference during the run.
    self.gen_names()

    if args.lower:
      self.run_lowering()

    if args.build_tb:
      self.run_build_tb()

    if args.build_sim:
      self.run_build_sim()

    if args.print_dot:
      self.run_print_dot()

    if args.hsdbg:
      self.run_hsdbg()
      return

    if args.run_sim:
      self.run_sim()

  def run_lowering(self):
    # Main HLS driver, for bring C to system verilog.
    print_step(f"Dynamically scheduled HLS'ing {args.kernel_file}...")

    if not args.mlir_kernel:
      # Run polygeist, generating affine/SCF level MLIR.
      runIfNotExists(
          self.kernel_affine,
          lambda: run_tool(
              [
                  os.path.join(POLYGEIST_BIN_DIR, "mlir-clang"),
                  "-S",  # Emit assembly (MLIR)
                  "--function=*",  # Emit all functions
                  "--memref-fullrank",  # Emit fullrank memrefs
                  "-scal-rep=0",  # see https://github.com/wsmoses/Polygeist/issues/142
                  args.kernel_file,
                  *args.extra_polygeist_kernel_args,
                  "|",  # pipe stdout
                  os.path.join(POLYGEIST_BIN_DIR, "polygeist-opt"
                              ),  # Run Polygeist optimization driver
                  "--canonicalize",  # ensure that the polygeist-emitted IR is canonical. This may remove some polygeist-dialect specific ops.
              ],
              self.kernel_affine,
              shell=True))
      print_info(f"Lowered to affine! (Polygeist)...! ({self.kernel_affine})")
    else:
      print_info("Skipping Polygeist lowering due to using an MLIR kernel")
      copyAllowSame(args.kernel_file, self.kernel_affine)

    if args.hs_kernel:
      print_info("Skipping handshake lowering due to using a handshake kernel")
      copyAllowSame(args.kernel_file, self.kernel_handshake)
      expectedStdKernel = os.path.join(os.path.dirname(args.kernel_file),
                                       args.kernel_name + "_std.mlir")
      if not os.path.exists(expectedStdKernel):
        print_error(
            f"Expected a standard kernel at {expectedStdKernel}. It is sufficient "
            "for this to just be a function signature without a definition, but it must be "
            "provided to describe the software interface of the handshake kernel."
        )
      else:
        copyAllowSame(expectedStdKernel, self.kernel_std)
    else:
      lowerAffine = self.genPrefixedOutputFileName("scf.mlir")
      runIfNotExists(
          lowerAffine, lambda: run_mlir_opt(
              ["--lower-affine"], self.kernel_affine, outputFile=lowerAffine))

      runIfNotExists(
          self.kernel_std, lambda: run_mlir_opt(["--convert-scf-to-std"],
                                                lowerAffine, self.kernel_std))

      # Run mem2reg to remove alloca's from the kernel. Then, canonicalize to
      # simplify control flow
      runIfNotExists(
          self.kernel_std_mem2reg, lambda: run_polygeist_opt(
              [
                  "--mem2reg",
                  "--canonicalize",
              ],
              self.kernel_std,
              self.kernel_std_mem2reg,
          ))

      runIfNotExists(
          self.kernel_std_flat,
          lambda: run_circt_opt(["--flatten-memref"], self.kernel_std_mem2reg,
                                self.kernel_std_flat))

      runIfNotExists(
          self.kernel_std_pushedconstants,
          lambda: run_hls_opt(["--push-constants"], self.kernel_std_flat, self.
                              kernel_std_pushedconstants))
      # From hereon, we should _not_ perform canonicalization while in standard;
      # this will undo the effects of --push-constants.

      # Put into maximized SSA form (precondition for correct handshake lowering)
      runIfNotExists(
          self.kernel_std_max,
          lambda: run_hls_opt(['--max-ssa=\"ignore-memref\"'], self.
                              kernel_std_pushedconstants, self.kernel_std_max))
      print_info(f"Lowered to standard...! ({self.kernel_std_max})")

      # Lower to handshake
      runIfNotExists(
          self.kernel_handshake_unbuffered, lambda: run_circt_opt([
              "-lower-std-to-handshake=\"source-constants\"", "--canonicalize",
              "--handshake-materialize-forks-sinks"
          ], self.kernel_std_max, self.kernel_handshake_unbuffered))

      # Add buffers
      runIfNotExists(
          self.kernel_handshake_buffered, lambda: run_circt_opt([
              f"-handshake-insert-buffers=\"strategy={args.buffer_strategy} buffer-size={args.buffer_size}\"",
              "--handshake-remove-simple-merges", "--canonicalize"
          ], self.kernel_handshake_unbuffered, self.kernel_handshake_buffered))

      # Run the add-ids pass to ensure that we have a deterministic mapping between
      # the FIRRTL/SV code and the Handshake IR/.dot file
      runIfNotExists(
          self.kernel_handshake, lambda: run_circt_opt([
              "-handshake-add-ids"
          ], self.kernel_handshake_buffered, self.kernel_handshake))
      print_info(f"Lowered to handshake...! ({self.kernel_handshake})")

    # Lower to FIRRTL
    runIfNotExists(
        self.kernel_firrtl,
        lambda: run_circt_opt(["--lower-handshake-to-firrtl"], self.
                              kernel_handshake, self.kernel_firrtl))
    print_info(f"Lowered to FIRRTL...! ({self.kernel_firrtl})")

    # Lower to SV
    runIfNotExists(
        self.kernel_sv, lambda: run_tool([
            os.path.join(CIRCT_BIN_DIR, "firtool"), "--verilog",
            "--format=mlir", self.kernel_firrtl
        ],
                                         self.kernel_sv,
                                         shell=True))
    print_info(f"Lowered to RTL...! ({self.kernel_sv})")

  def run_print_dot(self):
    print_step("Printing dot file of the handshake circuit...")
    run_circt_opt(["--handshake-print-dot"], self.kernel_handshake)

  def run_hsdbg(self):
    print_step("Running HSDbg on the handshake circuit...")
    hsdbg_cmd = [
        os.path.join(CIRCT_HLS_BIN_DIR, "hsdbg"), "-f dec",
        f"-p {args.hsdbg_port}", self.dotfile, args.vcd
    ]
    cmd = ["xterm", "-e", f'\'{" ".join(hsdbg_cmd)}\'']

    print_info(f"Starting HSDbg in separate terminal")
    proc = subprocess.Popen(" ".join(cmd),
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            shell=True)

  def run_genexec(self):
    pass

  def run_build_sim(self):
    print_step("Building simulator")

    # Generate HLT wrapper. This will create a '{kernel_name}.cpp' file in the
    # output directory.
    runIfNotExists(
        self.kernel_wrapper, lambda: run_tool([
            os.path.join(CIRCT_HLS_BIN_DIR, "hlt-wrapgen"
                        ), "--func", self.kernel_std_flat, "--ref", self.
            kernel_handshake, "--kernel", self.kernel_firrtl, "--name", args.
            kernel_name, "--type=handshakeFIRRTL", "-o", "."
        ],
                                              shell=True))
    print_info(f"Created HLT wrapper ({self.kernel_wrapper})")

    # Copy the prewritten CMakeLists.txt file to the output directory.
    # This is the file that does the heavy lifting in terms of configuring the
    # simulator library that we're building.
    htl_cmake = os.path.join(
        CIRCT_HLS_BIN_DIR, "..",
        "tools/hlt/Simulator/hlt_verilator_CMakeLists.txt")
    copyToCurrentDir(htl_cmake, "CMakeLists.txt")
    print_info("Added CMakeLists.txt to the build directory")

    # Remove any stale CMakeCache files
    if os.path.exists("CMakeCache.txt"):
      os.remove("CMakeCache.txt")

    # Run CMake and build the simulator library.
    cmake_args = ["-G", "Ninja"]
    cmake_args.append(f"-DHLT_TESTNAME={args.kernel_name}")
    # Enable tracing?
    if not args.no_trace:
      cmake_args.append(f"-DHLT_TRACE=1")
    cmake_args.append(f"-DHLT_THREADS={args.vlt_threads}")
    cmake_args.append(f"-DCMAKE_BUILD_TYPE=RelWithDebInfo")
    # Run cmake in current directory
    cmake_args.append(".")
    self.run_verilator_cmake(cmake_args)

  def run_verilator_cmake(self, cmake_args):
    # Iteratively try to run CMake and then ninja, and modify CMake arguments when
    # faced with some expected/common warnings.

    def handleErrorAndRetry(ret, cmake_args):
      print_info("Command failed. Trying to figure out what went wrong...")

      if "%Warning-UNOPTTHREADS" in ret.stdErr or "%Warning-UNOPTTHREADS" in ret.stdOut:
        cur_threads = [
            x if x.startswith("-DHLT_THREADS=") else "" for x in cmake_args
        ]
        cur_threads = [x.split("=")[1] for x in cur_threads if x != ""]
        cur_threads = int(cur_threads[0])
        next_threads = cur_threads - 1
        print_info(
            f"Verilator raised '%Warning-UNOPTTHREADS'; reducing model parallelism to {next_threads}"
        )
        cmake_args = [
            x for x in cmake_args if not x.startswith("-DHLT_THREADS")
        ]
        cmake_args.append(f"-DHLT_THREADS={next_threads}")
        self.run_verilator_cmake(cmake_args)
      else:
        print_info("Could not figure out what went wrong...")
        print_error(ret.stderr)

    ret = run_tool(["cmake", *cmake_args], exitOnError=False)
    if ret != None:
      return handleErrorAndRetry(ret, cmake_args)
    ret = run_tool(["ninja"], exitOnError=False)
    if ret != None:
      return handleErrorAndRetry(ret, cmake_args)

  def run_build_tb(self):
    print_step("Building testbench")

    # Lower polygeist to MLIR. Ensure to run polygeist canonicalization since
    # a lot of pointer/memref legalization takes places within the canonicalization
    # patterns of Polygeist.
    runIfNotExists(
        self.tb_poly,
        lambda: run_tool(
            [
                os.path.join(POLYGEIST_BIN_DIR, "mlir-clang"),
                "-S",  # Emit assembly (MLIR)
                "--function=*",  # Emit all functions
                "--memref-fullrank",  # Emit fullrank memrefs
                "-scal-rep=0",  # see https://github.com/wsmoses/Polygeist/issues/142
                args.tb_file,
                *args.extra_polygeist_tb_args,
                "|",  # pipe stdout
                os.path.join(POLYGEIST_BIN_DIR, "polygeist-opt"
                            ),  # Run Polygeist optimization driver
                "--canonicalize",  # ensure that the polygeist-emitted IR is canonical. This may remove some polygeist-dialect specific ops.
            ],
            self.tb_poly,
            shell=True))
    print_info(f"Lowered testbench to MLIR ({self.tb_poly})")

    runIfNotExists(
        self.tb_poly, lambda: run_polygeist_opt(["--lower-polygeist-ops"], self.
                                                tb_poly, self.tb_poly))

    # Run memref-call flattening. This is specific to handshake kernels since they do
    # not support multidimensional memories at the moment
    runIfNotExists(
        self.tb_poly_flat, lambda: run_circt_opt(
            ["--flatten-memref-calls"], self.tb_poly, self.tb_poly_flat))
    print_info(
        f"flattened multidimensional memref's in calls to unidimensional ({self.tb_poly_flat})"
    )

    tbFile = self.tb_poly_flat

    # Cosimulate?
    if args.cosim:
      # Rename the std kernel so we don't have a name collision with the RTL kernel.
      runIfNotExists(
          self.kernel_std_ref, lambda: run_hls_opt([
              f"--rename-func=\"f={args.kernel_name} to={self.kernel_name_ref}\""
          ], self.kernel_std, self.kernel_std_ref))

      # Add cosim.call to the testbench. We'll just do this inline, outside of the
      # predetermined names...
      run_hls_opt([
          f"--cosim-convert-call=\"from={args.kernel_name} ref={self.kernel_name_ref} targets={args.kernel_name}\"",
      ], self.tb_poly_flat, self.cosim_call)
      print_info(
          f"Added cosim call to ({self.cosim_call}). "
          f"Reference function is {self.kernel_name_ref} and target function is {args.kernel_name}"
      )

      # Lower cosim operations
      run_hls_opt([f"--cosim-lower-call"], self.cosim_call, self.cosim_compare)
      run_hls_opt([f"--cosim-lower-compare"], self.cosim_compare,
                  self.cosim_lowered)
      print_info(f"Lowered cosim operations in ({self.cosim_lowered})")

      # Move the std reference kernel into the test bench file. This is a simpler
      # way of resolving the symbol than the alternative (compile std kernel to
      # llvmir and then into a shared library, and finally link against that dynamically
      # at runtime).
      run_tool([
          os.path.join(CIRCT_HLS_BIN_DIR, "mlir-resolve"), "--file1",
          self.cosim_lowered, "--file2", self.kernel_std_ref
      ],
               stdOutFile=self.cosim_resolved,
               shell=True)
      print_info(
          f"Merged reference kernel {self.kernel_std_ref} into testbench {self.cosim_resolved}"
      )

      # Set the current point of the testbench to the cosim-lowered testbench
      tbFile = self.cosim_resolved

    # Asynchronize to adhere with HLT. We assume that the testname is equal to the
    # kernel name - which in turn is the function to asynchronize.
    runIfNotExists(
        self.tb_mlir, lambda: run_hls_opt([
            f"--asyncify-calls=\"function={args.kernel_name}\""
        ], tbFile, self.tb_mlir))
    print_info(f"Async-ified the testbench ({self.tb_mlir})")

    runIfNotExists(
        self.tb_llvm, lambda: run_mlir_opt([
            "-lower-affine", "-convert-scf-to-std", "-std-expand",
            "-convert-memref-to-llvm", "-convert-std-to-llvm",
            "-reconcile-unrealized-casts"
        ], self.tb_mlir, self.tb_llvm))
    print_info(f"Lowered testbench to LLVMIR ({self.tb_llvm})")

  def run_sim(self):
    print_step("Running testbench")
    # Directory containing LLVM libraries which we'll need to dynamically link
    # against in the mlir-cpu-runner
    libdir = os.path.join(LLVM_BIN_DIR, "..", "lib")

    # Shared library built by the simulator (see 'run_build_sim').
    simlib = f"libhlt_{args.kernel_name}.so"
    if not os.path.exists(simlib):
      print_error(
          f"Could not find {simlib}, expected to be built by the --build_sim step"
      )

    # Run the simulation.
    # The testbench side of things (which is in LLVM-MLIR format) is passed to
    # the mlir-cpu-runner and interpreted. The mlir-cpu-runner will look for the
    # provided entry point and start execution from there.
    # Within our lowered LLVM code, we have references to the (async) function
    # identifiers '{kernel_name}_call' and '{kernel_name}_await' (what is generated
    # by the HLT wrapper). Definitions for these functions are provided through
    # the simulator shared library (simlib).
    tb_cmd = " ".join([
        "mlir-cpu-runner", f"-e {args.tb_entry} -entry-point-result=i32 -O3",
        f"-shared-libs={libdir}/libmlir_c_runner_utils.so",
        f"-shared-libs={libdir}/libmlir_runner_utils.so",
        f"-shared-libs={simlib} {self.tb_llvm}"
    ])
    print_info(
        "WARNING: It has been observed that running the simulator through "
        "the hlstool script occasionally deadlocks the process. This is an unresolved "
        "issue. If you are experiencing this issue, please try running the simulation "
        "command directly on the command line.")
    print_info("Running simulator")
    run_tool([tb_cmd], self.tb_output, shell=True)

    print_info("Testbench ran successfully. Output is in {}".format(
        self.tb_output))
    if not args.no_trace and os.path.exists(args.vcd):
      print_info("VCD file is at: '{}'".format(args.vcd))


class StaticMode(HLSMode):
  # TODO: implement static mode

  def __init__(self):
    super().__init__('static')

  def add_arguments(self, subparser):
    pass


class MixedMode(HLSMode):
  # TODO: implement mixed dynamic/static mode

  def __init__(self):
    super().__init__('mixed')

  def add_arguments(self, subparser):
    pass


# Handles for the global 'Mode' objects
dynMode = DynamicMode()
staticMode = StaticMode()


# Loads a checkpoint file in the current directory
def load_checkpoint(args):
  if os.path.exists(".hlstool_checkpoint"):
    with open(".hlstool_checkpoint", "r") as f:
      checkpoint_args = json.load(f)
      # overwrite args with checkpoint args
      for key, value in checkpoint_args.items():
        vars(args)[key] = value
    print_info("Using input files from .hlstool_checkpoint")
    return True
  return False


def store_checkpoint(args):
  checkpoint_args = {}
  argsDict = vars(args)

  def addIfExists(key):
    if key in argsDict and argsDict[key] != None:
      checkpoint_args[key] = argsDict[key]

  with open(".hlstool_checkpoint", "w") as f:
    addIfExists("tb_file")
    addIfExists("kernel_file")
    addIfExists("kernel_name")

    f.write(json.dumps(checkpoint_args, indent=2, sort_keys=True))
  print_info(
      "Stored checkpoint to .hlstool_checkpoint. You can rerun HLSTool "
      "in this directory and pass the --checkpoint flag instead of providing "
      "paths and kernel names.")


def parse_args(parser):
  global mode
  global args
  args = parser.parse_args()
  print_header("Parsing and validating arguments")

  # First we validate the general arguments.
  if not args.tb_file and not args.kernel_file and not args.kernel_name:
    if not load_checkpoint(args):
      parser.error(
          "Must specify either testbench name (to infer kernel and kernel name)"
          " or kernel file and kernel name.")
  if args.tb_file and not args.kernel_file and not args.kernel_name:
    # Infer kernel file and name from testbench
    print_info("Inferring kernel file and name from testbench name.")
    dirname = os.path.dirname(args.tb_file)
    basename = os.path.basename(args.tb_file)
    basename = os.path.splitext(basename)[0]

    if not basename.startswith("tst_"):
      parser.error("Testbench name must start with 'tst_' in inference mode")
      sys.exit(1)

    basename = basename[4:]

    ext = ".c"
    if args.mlir_kernel:
      ext = ".mlir"
    args.kernel_file = os.path.join(dirname, basename + ext)
    args.kernel_name = basename
  elif not args.kernel_file and not args.kernel_name:
    parser.error("Must specify kernel file and kernel name")

  # Ensure provided files are absolute paths
  if args.tb_file:
    args.tb_file = os.path.abspath(args.tb_file)
  args.kernel_file = os.path.abspath(args.kernel_file)

  print_info("using kernel file: {}".format(args.kernel_file))
  print_info("using kernel name: {}".format(args.kernel_name))
  print_info("using testbench file: {}".format(args.tb_file))

  # Store checkpoint
  store_checkpoint(args)

  # Validate extra polygeist args
  if args.extra_polygeist_tb_args == None:
    args.extra_polygeist_tb_args = []
  else:
    args.extra_polygeist_tb_args = args.extra_polygeist_tb_args.split(" ")

  if args.extra_polygeist_kernel_args == None:
    args.extra_polygeist_kernel_args = []
  else:
    args.extra_polygeist_kernel_args = args.extra_polygeist_kernel_args.split(
        " ")

  # Set current mode
  if args.mode == 'dynamic':
    mode = dynMode
  elif args.mode == 'static':
    mode = staticMode
  else:
    parser.print_help()
    sys.exit(1)

  # Parse mode arguments
  print_step(f"Parsing '{mode.name}' mode arguments")
  mode.parse_arguments(parser)
  print_info("Arguments parsed and validated successfully!")


# An entry point
if __name__ == '__main__':
  # and argparser taking a mandatory argument "mode"
  parser = argparse.ArgumentParser(
      description="""
HLSTool is a tool for driving an end-to-end MLIR based HLS flow.


Usage:
Arguments are provided at two levels. First, generic arguments are specified, which
applies to any mode. The second level are mode specific arguments.
Generic arguments are specified before the (positional) mode argument.
To see the arguments for a specific mode, use\n
   'hlstool {mode} --help'
""",
      formatter_class=argparse.RawTextHelpFormatter)

  # A sub parser for the "dynamic" mode
  subparsers = parser.add_subparsers(help='Mode options', dest='mode')

  # General arguments
  parser.add_argument('--silent',
                      action='store_true',
                      help='Silent mode; suppress all output.',
                      default=False)

  parser.add_argument('--kernel_file',
                      type=str,
                      help='Path to the file containing the kernel.',
                      required=False)

  parser.add_argument(
      '--tb_file',
      type=str,
      help='Testbench file. If only this is specified, the kernel '
      'name and kernel file are inferred from the testbench name. '
      'When inferring this, testbenches are expected to be named \'tst_${kernel_name}.c\'.',
      required=False)

  parser.add_argument(
      '--tb_entry',
      type=str,
      help=
      'Testbench entry point. If not specified, the default entry point is used.',
      required=False,
      default='main')

  parser.add_argument(
      '--kernel_name',
      type=str,
      help='The kernel name is the name of the function within the '
      'kernel file which is to be compiled.',
      required=False)

  parser.add_argument('--outdir',
                      type=str,
                      help='Output directory. If not specified, '
                      'the output directory is the current working directory.',
                      required=False,
                      default=os.getcwd())

  parser.add_argument("--vcd",
                      type=str,
                      help="Path to a VCD file generated by the testbench.",
                      required=False)

  parser.add_argument("--no_trace",
                      action='store_true',
                      help="Disable tracing during simulation.",
                      required=False)
  parser.add_argument(
      "--vlt_threads",
      type=int,
      help="Number of Verilator threads to use. Defaults to the "
      "number of available threads / 2.",
      required=False,
      default=multiprocessing.cpu_count() // 2)

  parser.add_argument(
      "--rebuild",
      action='store_true',
      help="Always rebuild any output file of the tool. If this is not set, "
      "steps will be skipped when an expected output file already exists.",
      default=False)

  parser.add_argument(
      "--synth",
      action='store_true',
      help="Run Vivado and generate a resource estimate. An output text file "
      "will be generated in the output directory.")

  parser.add_argument(
      "--cosim",
      action='store_true',
      help="Modify and run the testbench in cosim mode. This requires that a "
      "software version of the kernel is available (standard MLIR).")

  parser.add_argument(
      "--checkpoint",
      action='store_true',
      help="Run HLSTool using a checkpoint file in the current directory. Each "
      "time HLSTool is executed, it will store a checkpoint file in the working "
      "directory which can be used to quickly reference the testbench and kernel "
      "files that was passed to HLSTool.")

  parser.add_argument(
      "--mlir_kernel",
      action='store_true',
      help="If set, the kernel is assumed to be an MLIR kernel. This will skip "
      "the Polygeist step. Kernel name inference via. testbench name still works, "
      "however, kernel file is expected to be suffixed with '.mlir'.")

  parser.add_argument(
      "--extra_polygeist_tb_args",
      type=str,
      help=
      "Extra arguments to pass to Polygeist during testbench lowering. Expects "
      "a space-delimited string.",
      required=False)

  parser.add_argument(
      "--extra_polygeist_kernel_args",
      type=str,
      help="Extra arguments to pass to Polygeist during kernel lowering. Expects "
      "a space-delimited string.",
      required=False)
  # Add mode arguments
  dynMode.add_arguments(subparsers)
  staticMode.add_arguments(subparsers)

  # Parse arguments
  parse_args(parser)

  # Move to the output directory
  os.chdir(args.outdir)
  print_info("Working directory is now {}".format(args.outdir))
  fileGraph = FileGraph(args.outdir)

  # Run the current mode
  print_header(f"Running '{mode.name}' mode")
  mode.run()
