#!/usr/bin/env python3
import argparse
import sys
import os
import subprocess
import shutil
import multiprocessing
import json
import re
from dataclasses import dataclass
from graphviz import Digraph

## CMake configured paths to the tools that we'll be using
CIRCT_BIN_DIR = "@CIRCT_BINARY_DIR@/bin/"
CIRCT_HLS_BIN_DIR = "@CIRCT_HLS_BINARY_DIR@/bin/"
CIRCT_HLS_SOURCE_DIR = "@CIRCT_HLS_SOURCE_DIR@"
LLVM_BIN_DIR = "@LLVM_BINARY_DIR@/bin"
POLYGEIST_BIN_DIR = "@POLYGEIST_BINARY_DIR@"


# Sanity check that the tools we need are available
def dirAndToolExists(replstr, dir, tool):
  if not dir or not os.path.exists(dir):
    print(
        f"Error: {dir} does not exist. Should have been generated from {replstr}"
    )
    sys.exit(1)
  if not os.path.exists(os.path.join(dir, tool)):
    print(f"Error: {tool} does not exist in {dir}")
    sys.exit(1)


dirAndToolExists("CIRCT_BINARY_DIR", CIRCT_BIN_DIR, "circt-opt")
dirAndToolExists("CIRCT_BINARY_DIR", CIRCT_BIN_DIR, "circt-translate")
dirAndToolExists("CIRCT_HLS_BINARY_DIR", CIRCT_HLS_BIN_DIR, "hls-opt")
dirAndToolExists("POLYGEIST_BINARY_DIR", POLYGEIST_BIN_DIR, "polygeist-opt")

## Global variables used to drive the tool
# Current mode
mode = None
# Tool arguments
args = None

# =============================================================================
# Print utilities
# =============================================================================


def print_header(text, width=80):
  if args.silent:
    return
  sideWidth = (width - len(text)) // 2 - 2
  print("=" * sideWidth + f" {text} " + "=" * sideWidth)


def print_prefixed(prefix, text):
  if args.silent:
    return
  print(f"{prefix}: {text}")


def print_info(text):
  print_prefixed("INFO", "    " + text)


def print_error(text):
  print_prefixed("ERROR", text)
  sys.exit(1)


def print_step(text):
  print_prefixed("\nSTEP", text)


def copyToCurrentDir(file, filename=None):
  hadFileName = filename is not None
  if filename is None:
    filename = os.path.basename(file)
  shutil.copy(file, filename)
  print_info("Copied '" + file + "' to current directory" +
             f" as {filename}" if hadFileName else "")


# =============================================================================
# Utilities for driving external tools
# =============================================================================


def copyAllowSame(src, dst):
  if os.path.exists(dst):
    if os.path.samefile(src, dst):
      print_info(f"File {dst} already exists, skipping copy...")
      return
  shutil.copy(src, dst)


def runIfNotExists(file, func):
  if not args.rebuild and os.path.exists(file):
    print_info(f"File {file} already exists, skipping...")
    return
  func()


def isFile(file):
  # if file is a file and has an extension
  return os.path.isfile(file) and os.path.splitext(file)[1] != ""


def splitAtEveryNCharacters(string, n):
  return "\\n".join([string[i:i + n] for i in range(0, len(string), n)])


class FileGraph:
  # This is a class for visualizing the different files generated by the tool
  # and the calls between them.
  def __init__(self, outdir):
    self.graph = Digraph("HLSTool Graph",
                         filename=os.path.join(outdir, "hlstool.dot"))
    self.graph.save()

  def add_relation(self, edgeStr, candidateInputs, candidateOutputs=None):
    # Filter candidate inputs based on which of them are actual files
    inputs = [node for node in candidateInputs if node and isFile(node)]
    # Filter candidate outputs based on which of them are actual files
    outputs = [node for node in candidateOutputs if node and isFile(node)]

    # Add edges between the inputs and outputs
    for input in inputs:
      for output in outputs:
        self.graph.edge(input,
                        output,
                        label=splitAtEveryNCharacters(edgeStr, 40))

    self.graph.save()


fileGraph = None


@dataclass
class RunResult:
  returnCode: int
  stdOut: str
  stdErr: str


def run_tool(args,
             stdOutFile=None,
             shell=False,
             liveOutput=False,
             exitOnError=True):
  cmd = " ".join(args)

  infostr = f"Running: {cmd}"
  if stdOutFile:
    infostr += f" > {stdOutFile}"
  print_info(infostr)

  # Register any possible I/O file relations with the file graph
  fileGraph.add_relation(cmd, args, [stdOutFile])

  def onError(returnCode, stdOut, stdErr):
    stdErr = str(stdErr).replace("\\n", "\n")
    print_error(
        f"Error while executing: {cmd}\nstdout:\n{stdOut}\nstderr:\n{stdErr}\n (code: {returnCode})"
    )

  try:
    if shell:
      proc = subprocess.Popen(cmd,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE,
                              shell=True)
      if liveOutput:
        # Continuously poll the process and forward any stdout
        while not proc.poll():
          stdoutdata = proc.stdout.readline()
          if stdoutdata:
            sys.stdout.write(stdoutdata.decode("utf-8"))
          else:
            code = proc.returncode
            break
          stdOut, stdErr = b'', b''
      else:
        stdOut, stdErr = proc.communicate()
        code = proc.returncode
    else:
      res = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
      code = res.returncode
      stdOut, stdErr = res.stdout, res.stderr

    stdOut = stdOut.decode("utf-8")
    stdErr = stdErr.decode("utf-8")

    if code:
      if exitOnError:
        onError(code, stdOut, stdErr)
      else:
        # Just forward the stdout, stderr and exit code to the caller
        return RunResult(code, stdOut, stdErr)

    if stdOutFile:
      with open(stdOutFile, 'w') as f:
        f.write(stdOut)
  except subprocess.CalledProcessError as e:
    onError(e.returncode, "<<subprocess CALLED PROCESS ERROR>>", e.output)


def run_fud(fromType, toType, inputFile, outputFile):
  if fromType == "" or toType == "":
    print_error("Error: Missing fromType or toType")
  run_tool([
      "fud", "exec", "--from", fromType, "--to", toType, "-o", outputFile,
      inputFile
  ])


def run_opt_tool(tool_dir, tool_name, args, inputFile=None, outputFile=None):
  args = [os.path.join(tool_dir, tool_name), *args]
  if inputFile:
    args.append(inputFile)
  args.append("--allow-unregistered-dialect")
  run_tool(args, outputFile, shell=True)


def run_polygeist_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(POLYGEIST_BIN_DIR, "polygeist-opt", args, inputFile, outputFile)


def run_circt_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(CIRCT_BIN_DIR, "circt-opt", args, inputFile, outputFile)


def run_circt_translate(args, inputFile=None, outputFile=None):
  run_opt_tool(CIRCT_BIN_DIR, "circt-translate", args, inputFile, outputFile)


def run_hls_opt(args, inputFile=None, outputFile=None):
  run_opt_tool(CIRCT_HLS_BIN_DIR, "hls-opt", args, inputFile, outputFile)


def run_mlir_opt(args, inputFile, outputFile=None):
  run_opt_tool(LLVM_BIN_DIR, "mlir-opt", args, inputFile, outputFile)


class HLSMode:

  def __init__(self, name):
    self.name = name

  def add_arguments(self, subparser):
    raise NotImplementedError("implement me in a subclass")

  def parse_arguments(self, parser):
    raise NotImplementedError("implement me in a subclass")

  def genPrefixedOutputFileName(self, suffix):
    return os.path.join(args.outdir, args.kernel_name + "_" + suffix)

  def gen_names(self):
    # Generates all possible output file names which we'll reference during the run.
    # Kernel files
    self.kernel_sv = os.path.join(args.outdir, args.kernel_name + ".sv")
    self.dotfile = os.path.join(args.outdir, args.kernel_name + ".dot")

    # Analysis files
    self.resource_estimate = os.path.join(
        args.outdir, args.kernel_name + "_resource_estimate.txt")

    # Mode-specific names
    self.gen_names_mode()

  def run(self):
    # Generate output file names used during the run.
    self.gen_names()

    # Top level runner. Non-mode specific run jobs
    # ...

    # Run mode specific jobs
    self.run_mode()

    # Run post-mode specific jobs
    if args.synth:
      self.run_synth()

    print_header("Finished!")

  def run_synth(self):
    print_step("Running Vivado resource estimation")

    # Copy .tcl and .xdc files to current directory
    copyToCurrentDir(
        os.path.join(CIRCT_HLS_SOURCE_DIR, "tools", "hlstool", "synth.tcl"))
    copyToCurrentDir(
        os.path.join(CIRCT_HLS_SOURCE_DIR, "tools", "hlstool", "device.xdc"))

    # Generate run commands
    vivado_args = ["vivado", "-mode", "batch", "-source", "synth.tcl"]
    # synth arguments (see synth.tcl)
    vivado_args.append("-tclargs")
    vivado_args.append(args.kernel_name)  # top level
    vivado_args.append("xczu3eg-sbva484-1-e")  # part
    vivado_args.append("vivado")  # outdir
    vivado_args.append("1")  # do routing

    print_info("Running Vivado with command: " + " ".join(vivado_args))
    run_tool(vivado_args, shell=True, liveOutput=not args.silent)


# Mode for supporting HLT simulations
class HLTMode():

  def add_arguments(self, subparser):
    subparser.add_argument('--run_sim',
                           action='store_true',
                           help='Run the HLT testbench.')

    subparser.add_argument(
        '-e',
        '--genexec',
        type=str,
        help="Generate a HLT testbench which compiles to an executable file. "
        "This is useful if you don\'t want to run the HLT wrapper via. the "
        "mlir-cpu-runner, but instead want an executable file that you can debug"
        " with regular C++ tools")

    subparser.add_argument(
        '--build_sim',
        action='store_true',
        help="Lower the C code to hardware, build the simulator.")
    subparser.add_argument(
        '--build_tb',
        action='store_true',
        help=
        "Lower the testbench to MLIR, asyncify it (for HLT use), convert to LLVM IR."
    )

  def gen_names_mode(self):
    # Testbench files
    self.tb_poly = os.path.join(args.outdir, args.kernel_name + "_poly.mlir")
    self.tb_poly_flat = os.path.join(args.outdir,
                                     args.kernel_name + "_poly_flat.mlir")
    self.tb_mlir = os.path.join(args.outdir, args.kernel_name + "_tb.mlir")
    self.tb_llvm = os.path.join(args.outdir, args.kernel_name + "_tb_llvm.mlir")
    self.tb_output = os.path.join(args.outdir,
                                  args.kernel_name + "_tb_output.txt")
    self.cosim_call = os.path.join(args.outdir,
                                   args.kernel_name + "_tb_cosim_call.mlir")
    self.cosim_compare = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_compare.mlir")
    self.cosim_lowered = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_lowered.mlir")
    self.cosim_resolved = os.path.join(
        args.outdir, args.kernel_name + "_tb_cosim_resolved.mlir")
    self.kernel_wrapper = os.path.join(args.outdir, args.kernel_name + ".cpp")

  def hlt_kernel_file(self):
    raise NotImplementedError(
        "A subclass must return the name of the file used to drive the --kernel command in HLT wrapgen."
    )

  def hlt_func_file(self):
    raise NotImplementedError(
        "A subclass must return the name of the file used to drive the --func command in HLT wrapgen."
    )

  def hlt_ref_file(self):
    raise NotImplementedError(
        "A subclass must return the name of the file used to drive the --ref command in HLT wrapgen."
    )

  def run_create_hlt_wrapper(self):
    hlt_args = [os.path.join(CIRCT_HLS_BIN_DIR, "hlt-wrapgen")]
    if self.hlt_func_file():
      hlt_args += ["--func", self.hlt_func_file()]
    if self.hlt_ref_file():
      hlt_args += ["--ref", self.hlt_ref_file()]
    if self.hlt_kernel_file():
      hlt_args += ["--kernel", self.hlt_kernel_file()]
    hlt_args.append(f"--type={self.hlt_type()}")
    hlt_args += ["--name", args.kernel_name]
    hlt_args += ["-o", "."]
    run_tool(hlt_args, shell=True)

  def run_build_sim(self):
    print_step("Building simulator")

    # Generate HLT wrapper. This will create a '{kernel_name}.cpp' file in the
    # output directory.
    self.run_create_hlt_wrapper()
    print_info(f"Created HLT wrapper ({self.kernel_wrapper})")

    # Copy the prewritten CMakeLists.txt file to the output directory.
    # This is the file that does the heavy lifting in terms of configuring the
    # simulator library that we're building.
    htl_cmake = os.path.join(
        CIRCT_HLS_BIN_DIR, "..",
        "tools/hlt/Simulator/hlt_verilator_CMakeLists.txt")
    copyToCurrentDir(htl_cmake, "CMakeLists.txt")
    print_info("Added CMakeLists.txt to the build directory")

    # Remove any stale CMakeCache files
    if os.path.exists("CMakeCache.txt"):
      os.remove("CMakeCache.txt")

    # Run CMake and build the simulator library.
    cmake_args = ["-G", "Ninja"]
    cmake_args.append(f"-DHLT_TESTNAME={args.kernel_name}")
    # Enable tracing?
    if not args.no_trace:
      cmake_args.append(f"-DHLT_TRACE=1")
    cmake_args.append(f"-DHLT_THREADS={args.vlt_threads}")
    cmake_args.append(f"-DCMAKE_BUILD_TYPE=RelWithDebInfo")
    # Run cmake in current directory
    cmake_args.append(".")
    self.run_verilator_cmake(cmake_args)

  def run_verilator_cmake(self, cmake_args):
    # Iteratively try to run CMake and then ninja, and modify CMake arguments when
    # faced with some expected/common warnings.

    def handleErrorAndRetry(ret, cmake_args):
      print_info("Command failed. Trying to figure out what went wrong...")

      if "%Warning-UNOPTTHREADS" in ret.stdErr or "%Warning-UNOPTTHREADS" in ret.stdOut:
        cur_threads = [
            x if x.startswith("-DHLT_THREADS=") else "" for x in cmake_args
        ]
        cur_threads = [x.split("=")[1] for x in cur_threads if x != ""]
        cur_threads = int(cur_threads[0])
        next_threads = cur_threads - 1
        print_info(
            f"Verilator raised '%Warning-UNOPTTHREADS'; reducing model parallelism to {next_threads}"
        )
        cmake_args = [
            x for x in cmake_args if not x.startswith("-DHLT_THREADS")
        ]
        cmake_args.append(f"-DHLT_THREADS={next_threads}")
        self.run_verilator_cmake(cmake_args)
      else:
        print_info("Could not figure out what went wrong...")
        print_error(ret.stdErr)

    ret = run_tool(["cmake", *cmake_args], exitOnError=False)
    if ret != None:
      return handleErrorAndRetry(ret, cmake_args)
    ret = run_tool(["ninja"], exitOnError=False)
    if ret != None:
      return handleErrorAndRetry(ret, cmake_args)

  def run_build_tb(self):
    print_step("Building testbench")

    # Lower polygeist to MLIR. Ensure to run polygeist canonicalization since
    # a lot of pointer/memref legalization takes places within the canonicalization
    # patterns of Polygeist.
    runIfNotExists(
        self.tb_poly,
        lambda: run_tool(
            [
                os.path.join(POLYGEIST_BIN_DIR, "mlir-clang"),
                "-S",  # Emit assembly (MLIR)
                "--function=*",  # Emit all functions
                "--memref-fullrank",  # Emit fullrank memrefs
                "-scal-rep=0",  # see https://github.com/wsmoses/Polygeist/issues/142
                args.tb_file,
                *args.extra_polygeist_tb_args,
                "|",  # pipe stdout
                os.path.join(POLYGEIST_BIN_DIR, "polygeist-opt"
                            ),  # Run Polygeist optimization driver
                "--canonicalize",  # ensure that the polygeist-emitted IR is canonical. This may remove some polygeist-dialect specific ops.
            ],
            self.tb_poly,
            shell=True))
    print_info(f"Lowered testbench to MLIR ({self.tb_poly})")

    runIfNotExists(
        self.tb_poly, lambda: run_polygeist_opt(["--lower-polygeist-ops"], self.
                                                tb_poly, self.tb_poly))

    # Run memref-call flattening. This is specific to handshake kernels since they do
    # not support multidimensional memories at the moment
    runIfNotExists(
        self.tb_poly_flat, lambda: run_circt_opt(
            ["--flatten-memref-calls"], self.tb_poly, self.tb_poly_flat))
    print_info(
        f"flattened multidimensional memref's in calls to unidimensional ({self.tb_poly_flat})"
    )

    tbFile = self.tb_poly_flat

    # Cosimulate?
    if args.cosim:
      # Rename the cf kernel so we don't have a name collision with the RTL kernel.
      runIfNotExists(
          self.kernel_cf_ref, lambda: run_hls_opt([
              f"--rename-func=\"f={args.kernel_name} to={self.kernel_name_ref}\""
          ], self.kernel_cf, self.kernel_cf_ref))

      # Add cosim.call to the testbench. We'll just do this inline, outside of the
      # predetermined names...
      run_hls_opt([
          f"--cosim-convert-call=\"from={args.kernel_name} ref={self.kernel_name_ref} targets={args.kernel_name}\"",
      ], self.tb_poly_flat, self.cosim_call)
      print_info(
          f"Added cosim call to ({self.cosim_call}). "
          f"Reference function is {self.kernel_name_ref} and target function is {args.kernel_name}"
      )

      # Lower cosim operations
      run_hls_opt([f"--cosim-lower-call"], self.cosim_call, self.cosim_compare)
      run_hls_opt([f"--cosim-lower-compare"], self.cosim_compare,
                  self.cosim_lowered)
      print_info(f"Lowered cosim operations in ({self.cosim_lowered})")

      # Move the cf reference kernel into the test bench file. This is a simpler
      # way of resolving the symbol than the alternative (compile cf kernel to
      # llvmir and then into a shared library, and finally link against that dynamically
      # at runtime).
      run_tool([
          os.path.join(CIRCT_HLS_BIN_DIR, "mlir-resolve"), "--file1",
          self.cosim_lowered, "--file2", self.kernel_cf_ref
      ],
               cfOutFile=self.cosim_resolved,
               shell=True)
      print_info(
          f"Merged reference kernel {self.kernel_cf_ref} into testbench {self.cosim_resolved}"
      )

      # Set the current point of the testbench to the cosim-lowered testbench
      tbFile = self.cosim_resolved

    # Asynchronize to adhere with HLT. We assume that the testname is equal to the
    # kernel name - which in turn is the function to asynchronize.
    runIfNotExists(
        self.tb_mlir, lambda: run_hls_opt([
            f"--asyncify-calls=\"function={args.kernel_name}\""
        ], tbFile, self.tb_mlir))
    print_info(f"Async-ified the testbench ({self.tb_mlir})")

    LLVM_LOWERING_ORDER = [
        "-lower-affine", "-convert-math-to-llvm", "-convert-arith-to-llvm",
        "-convert-scf-to-cf", "-convert-memref-to-llvm",
        "-convert-func-to-llvm", "-convert-cf-to-llvm",
        "-reconcile-unrealized-casts"
    ]

    runIfNotExists(
        self.tb_llvm,
        lambda: run_mlir_opt(LLVM_LOWERING_ORDER, self.tb_mlir, self.tb_llvm))
    print_info(f"Lowered testbench to LLVMIR ({self.tb_llvm})")

  def run_sim(self):
    print_step("Running testbench")
    # Directory containing LLVM libraries which we'll need to dynamically link
    # against in the mlir-cpu-runner
    libdir = os.path.join(LLVM_BIN_DIR, "..", "lib")

    # Shared library built by the simulator (see 'run_build_sim').
    simlib = f"libhlt_{args.kernel_name}.so"
    if not os.path.exists(simlib):
      print_error(
          f"Could not find {simlib}, expected to be built by the --build_sim step"
      )

    # Run the simulation.
    # The testbench side of things (which is in LLVM-MLIR format) is passed to
    # the mlir-cpu-runner and interpreted. The mlir-cpu-runner will look for the
    # provided entry point and start execution from there.
    # Within our lowered LLVM code, we have references to the (async) function
    # identifiers '{kernel_name}_call' and '{kernel_name}_await' (what is generated
    # by the HLT wrapper). Definitions for these functions are provided through
    # the simulator shared library (simlib).
    tb_cmd = " ".join([
        "mlir-cpu-runner", f"-e {args.tb_entry} -entry-point-result=i32 -O3",
        f"-shared-libs={libdir}/libmlir_c_runner_utils.so",
        f"-shared-libs={libdir}/libmlir_runner_utils.so",
        f"-shared-libs={args.outdir}/{simlib} {self.tb_llvm}"
    ])
    print_info(
        "WARNING: It has been observed that running the simulator through "
        "the hlstool script occasionally deadlocks the process. This is an unresolved "
        "issue. If you are experiencing this issue, please try running the simulation "
        "command directly on the command line.")
    print_info("Running simulator")
    run_tool([tb_cmd], self.tb_output, shell=True)

    print_info("Testbench ran successfully. Output is in {}".format(
        self.tb_output))
    if not args.no_trace and os.path.exists(args.vcd):
      print_info("VCD file is at: '{}'".format(args.vcd))


# Mode class for dynamically scheduled HLS flows
class DynamicMode(HLSMode, HLTMode):

  def __init__(self, name='dynamic'):
    super().__init__(name)

  def add_arguments(self, subparser):
    HLTMode.add_arguments(self, subparser)

    subparser.add_argument(
        '--print_dot',
        help="Prints a dot file of the "
        "handshake circuit",
        action='store_true',
    )
    subparser.add_argument('--lower',
                           action='store_true',
                           help="Lower the C code to hardware.")
    subparser.add_argument(
        '--hsdbg',
        action='store_true',
        help="Run HSDbg on the circuit. This"
        " assumes that a simulation has been run prior to this.")

    subparser.add_argument('--hsdbg_port',
                           type=int,
                           default=8080,
                           help="Port to run HSDbg server on.")

    subparser.add_argument(
        '--hs_kernel',
        action='store_true',
        help="The kernel is a handshake kernel. If this is set, will skip "
        "polygaist and standard to handshake lowering.")

    subparser.add_argument(
        '--flatten_firrtl',
        action='store_true',
        help="Flattens the handshake top-level FIRRTL component.",
        default=False)

    subparser.add_argument(
        '--buffer_strategy',
        type=str,
        default="cycles",
        help="Buffer strategy to use, see 'circt-opt --handshake-insert-buffers'"
    )

    subparser.add_argument(
        '--buffer_size',
        type=int,
        default=2,
        help=
        "Number of slots in each buffer, see 'circt-opt --handshake-insert-buffers'"
    )

  def hlt_func_file(self):
    return self.kernel_cf_flat

  def hlt_kernel_file(self):
    return self.kernel_firrtl

  def hlt_ref_file(self):
    return self.kernel_handshake

  def hlt_type(self):
    return "handshakeFIRRTL"

  def parse_arguments(self, parser):
    if not args.vcd:
      # Infer a default location for the VCD file based on how HLT emits it.
      args.vcd = os.path.join(args.outdir, 'logs/vlt_dump.vcd')

    if args.hsdbg:
      # Always run print_dot
      args.print_dot |= True

      # If we are running HSDbg there must be simulation results available
      if not os.path.exists(args.vcd):
        parser.error(f"Expected a simulation result file at {args.vcd}. "
                     " Please run a simulation first.")

    if not args.build_sim and not args.lower and not args.run_sim and not \
      args.build_tb and not args.synth and not args.hsdbg:
      # If no specific end-point has been set, we'll stop at building the sim
      # and kernel, but not running the sim.
      print_info("enabling --build_sim due to no specific end-point set")
      args.build_sim |= True
      if args.tb_file:
        print_info("enabling --build_tb due to no specific end-point set")
        args.build_tb |= True

    if args.synth:
      args.lower |= True
      print_info("enabling --lower required by --synth")

    if args.run_sim:
      # Running the sim requires building the sim
      args.build_sim |= True
      args.build_tb |= True
      print_info("enabling --build_sim required by --run_sim")
      print_info("enabling --build_tb required by --run_sim")

    if args.build_sim:
      # Building the sim requires lowering the kernel.
      args.lower |= True
      print_info("enabling --lower required by --build_sim")

  def gen_names_mode(self):
    # Generate dynamic-mode specific names.

    # Kernel files
    self.kernel_affine = self.genPrefixedOutputFileName("affine.mlir")
    self.kernel_cf = self.genPrefixedOutputFileName("cf.mlir")
    self.kernel_cf_mem2reg = self.genPrefixedOutputFileName("cf_mem2reg.mlir")
    self.kernel_cf_pushedconstants = self.genPrefixedOutputFileName(
        "cf_pushedconstants.mlir")
    self.kernel_cf_flat = self.genPrefixedOutputFileName("cf_flat.mlir")
    # A renamed version of the kernel wherein the function name does not clash with
    # the name of the handshake kernel.
    self.kernel_cf_ref = self.genPrefixedOutputFileName("cf_ref.mlir")
    self.kernel_name_ref = args.kernel_name + "_ref"

    self.kernel_cf_max = self.genPrefixedOutputFileName("cf_max.mlir")
    self.kernel_handshake = self.genPrefixedOutputFileName("handshake.mlir")
    self.kernel_handshake_buffered = self.genPrefixedOutputFileName(
        "handshake_buffered.mlir")
    self.kernel_handshake_unbuffered = self.genPrefixedOutputFileName(
        "handshake_unbuffered.mlir")
    self.kernel_firrtl = self.genPrefixedOutputFileName("firrtl.mlir")

    # HLT mode names
    HLTMode.gen_names_mode(self)

  def run_mode(self):
    # First, generate all of the names that we'll reference during the run.
    self.gen_names()

    if args.lower:
      self.run_lowering()

    if args.build_tb:
      self.run_build_tb()

    if args.build_sim:
      self.run_build_sim()

    if args.print_dot:
      self.run_print_dot()

    if args.hsdbg:
      self.run_hsdbg()
      return

    if args.run_sim:
      self.run_sim()

  def run_lowering(self):
    # Handshake lowering.
    # In cases where a handshake kernel has not been provided, we expect that an
    # inheriting pass has written a file to self.kernel_affine.
    print_step(f"Dynamically scheduled HLS'ing {args.kernel_file}...")

    if args.hs_kernel:
      print_info("Skipping handshake lowering due to using a handshake kernel")
      copyAllowSame(args.kernel_file, self.kernel_handshake)
      expectedStdKernel = os.path.join(os.path.dirname(args.kernel_file),
                                       args.kernel_name + "_cf.mlir")
      if not os.path.exists(expectedStdKernel):
        print_error(
            f"Expected a standard kernel at {expectedStdKernel}. It is sufficient "
            "for this to just be a function signature without a definition, but it must be "
            "provided to describe the software interface of the handshake kernel."
        )
      else:
        copyAllowSame(expectedStdKernel, self.kernel_cf)
        # A flattened cf kernel representation is required for the simulator.
        runIfNotExists(
            self.kernel_cf_flat, lambda: run_circt_opt(
                ["--flatten-memref"], self.kernel_cf, self.kernel_cf_flat))
    else:
      lowerAffine = self.genPrefixedOutputFileName("scf.mlir")
      runIfNotExists(
          lowerAffine, lambda: run_mlir_opt(
              ["--lower-affine"], self.kernel_affine, outputFile=lowerAffine))

      runIfNotExists(
          self.kernel_cf, lambda: run_mlir_opt(["--convert-scf-to-cf"],
                                               lowerAffine, self.kernel_cf))

      # Run mem2reg to remove alloca's from the kernel. Then, canonicalize to
      # simplify control flow
      runIfNotExists(
          self.kernel_cf_mem2reg, lambda: run_polygeist_opt(
              [
                  "--mem2reg",
                  "--canonicalize",
              ],
              self.kernel_cf,
              self.kernel_cf_mem2reg,
          ))

      runIfNotExists(
          self.kernel_cf_flat,
          lambda: run_circt_opt(["--flatten-memref"], self.kernel_cf_mem2reg,
                                self.kernel_cf_flat))

      runIfNotExists(
          self.kernel_cf_pushedconstants,
          lambda: run_hls_opt(["--push-constants"], self.kernel_cf_flat, self.
                              kernel_cf_pushedconstants))
      # From hereon, we should _not_ perform canonicalization while in standard;
      # this will undo the effects of --push-constants.

      # Put into maximized SSA form (precondition for correct handshake lowering)
      runIfNotExists(
          self.kernel_cf_max,
          lambda: run_hls_opt(['--max-ssa=\"ignore-memref\"'], self.
                              kernel_cf_pushedconstants, self.kernel_cf_max))
      print_info(f"Lowered to standard...! ({self.kernel_cf_max})")

      # Lower to handshake
      runIfNotExists(
          self.kernel_handshake_unbuffered, lambda: run_circt_opt([
              "-lower-std-to-handshake=\"source-constants\"", "--canonicalize",
              "--handshake-materialize-forks-sinks"
          ], self.kernel_cf_max, self.kernel_handshake_unbuffered))

      # Add buffers
      runIfNotExists(
          self.kernel_handshake_buffered, lambda: run_circt_opt([
              f"-handshake-insert-buffers=\"strategy={args.buffer_strategy} buffer-size={args.buffer_size}\"",
              "--canonicalize"
          ], self.kernel_handshake_unbuffered, self.kernel_handshake_buffered))

      # Run the add-ids pass to ensure that we have a deterministic mapping between
      # the FIRRTL/SV code and the Handshake IR/.dot file
      runIfNotExists(
          self.kernel_handshake, lambda: run_circt_opt([
              "-handshake-add-ids"
          ], self.kernel_handshake_buffered, self.kernel_handshake))
      print_info(f"Lowered to handshake...! ({self.kernel_handshake})")

    # Lower to FIRRTL
    lowerToFIRRTLArg = "--lower-handshake-to-firrtl"
    if args.flatten_firrtl:
      lowerToFIRRTLArg += "=\"flatten\""
    runIfNotExists(
        self.kernel_firrtl, lambda: run_circt_opt(
            [lowerToFIRRTLArg], self.kernel_handshake, self.kernel_firrtl))
    print_info(f"Lowered to FIRRTL...! ({self.kernel_firrtl})")

    # Lower to SV
    runIfNotExists(
        self.kernel_sv, lambda: run_tool([
            os.path.join(CIRCT_BIN_DIR, "firtool"), "--verilog",
            "--format=mlir", "--allow-unregistered-dialect", self.kernel_firrtl
        ],
                                         self.kernel_sv,
                                         shell=True))
    print_info(f"Lowered to RTL...! ({self.kernel_sv})")

  def run_print_dot(self):
    print_step("Printing dot file of the handshake circuit...")
    run_circt_opt(["--handshake-print-dot"], self.kernel_handshake)

  def run_hsdbg(self):
    print_step("Running HSDbg on the handshake circuit...")
    hsdbg_cmd = [
        os.path.join(CIRCT_HLS_BIN_DIR, "hsdbg"), "handshake", "-f dec",
        f"-p {args.hsdbg_port}", "--dot", self.dotfile, "--vcd", args.vcd
    ]
    cmd = ["xterm", "-e", f'\'{" ".join(hsdbg_cmd)}\'']

    print_info(f"Starting HSDbg in separate terminal")
    proc = subprocess.Popen(" ".join(cmd),
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            shell=True)

  def run_genexec(self):
    pass


class PolygeistMode:

  def run_polygeist(self):
    # Run polygeist, generating affine/SCF level MLIR.
    runIfNotExists(
        self.kernel_affine,
        lambda: run_tool(
            [
                os.path.join(POLYGEIST_BIN_DIR, "mlir-clang"),
                "-S",  # Emit assembly (MLIR)
                "--function=*",  # Emit all functions
                "--memref-fullrank",  # Emit fullrank memrefs
                "-scal-rep=0",  # see https://github.com/wsmoses/Polygeist/issues/142
                args.kernel_file,
                *args.extra_polygeist_kernel_args,
                "|",  # pipe stdout
                os.path.join(POLYGEIST_BIN_DIR, "polygeist-opt"
                            ),  # Run Polygeist optimization driver
                "--canonicalize",  # ensure that the polygeist-emitted IR is canonical. This may remove some polygeist-dialect specific ops.
            ],
            self.kernel_affine,
            shell=True))
    print_info(f"Lowered to affine! (Polygeist)...! ({self.kernel_affine})")


class PolygeistDynamicMode(DynamicMode, PolygeistMode):

  def __init__(self):
    super().__init__('dynamic-polygeist')

  def create_subparser(self, subparser):
    return subparser.add_parser(self.name,
                                help='Dynamic mode (from C through Polygeist)')

  def run_lowering(self):
    if not args.mlir_kernel:
      self.run_polygeist()
    else:
      print_info("Skipping Polygeist lowering due to using an MLIR kernel")
      copyAllowSame(args.kernel_file, self.kernel_affine)

    # Transition to handshake lowering
    DynamicMode.run_lowering(self)


class StaticMode(HLSMode, HLTMode):

  def __init__(self, name='static'):
    super().__init__(name)

  def add_arguments(self, subparser):
    HLTMode.add_arguments(self, subparser)
    subparser.add_argument('--pipeline',
                           action='store_true',
                           help="Pipelines the loops at the Affine level.",
                           default=False)

  def parse_arguments(self, subparser):
    if args.run_sim:
      # Running the sim requires building the sim
      args.build_sim |= True
      args.build_tb |= True
      print_info("enabling --build_sim required by --run_sim")
      print_info("enabling --build_tb required by --run_sim")

  def gen_names_mode(self):
    self.kernel_affine = self.genPrefixedOutputFileName("affine.mlir")
    self.kernel_scf = self.genPrefixedOutputFileName("scf.mlir")
    self.kernel_staticlogic = self.genPrefixedOutputFileName("staticlogic.mlir")
    self.kernel_calyx = self.genPrefixedOutputFileName("calyx.mlir")
    self.kernel_calyx_futil = self.genPrefixedOutputFileName("calyx.futil")

    HLTMode.gen_names_mode(self)

  def run_mode(self):
    self.gen_names()
    self.run_lowering()

    if args.build_tb:
      self.run_build_tb()

    if args.build_sim:
      self.run_build_sim()

    if args.run_sim:
      self.run_sim()

  def hlt_func_file(self):
    # SCF defines the software interface
    return self.kernel_scf

  def hlt_kernel_file(self):
    # No kernel file
    return None

  def hlt_ref_file(self):
    # Calyx defines the reference file
    return self.kernel_calyx

  def hlt_type(self):
    return "calyx"

  def run_lowering(self):
    print_step(f"Statically scheduled HLS'ing {args.kernel_file}...")

    if args.pipeline:
      runIfNotExists(
          self.kernel_staticlogic, lambda: run_circt_opt([
              "--convert-affine-to-staticlogic",
          ], self.kernel_affine, self.kernel_staticlogic))
      lowered_loops = self.kernel_staticlogic
    else:
      runIfNotExists(
          self.kernel_scf, lambda: run_mlir_opt([
              "--lower-affine",
              "--scf-for-to-while",
          ], self.kernel_affine, self.kernel_scf))
      lowered_loops = self.kernel_scf
    print_info(f"Lowered to loops...! ({lowered_loops})")

    runIfNotExists(
        self.kernel_calyx, lambda: run_circt_opt([
            f"--lower-scf-to-calyx=\"top-level-function={args.method}\""
        ], lowered_loops, self.kernel_calyx))
    print_info(f"Lowered to Calyx MLIR...! ({self.kernel_calyx})")

    runIfNotExists(
        self.kernel_calyx_futil, lambda: run_circt_translate(
            ["--export-calyx"], self.kernel_calyx, self.kernel_calyx_futil))
    print_info(f"Lowered to Calyx Futil...! ({self.kernel_calyx_futil})")

    runIfNotExists(
        self.kernel_sv, lambda: run_fud("futil", "verilog", self.
                                        kernel_calyx_futil, self.kernel_sv))
    print_info(f"Lowered to RTL...! ({self.kernel_sv})")


class TorchMode:

  PASSES = ",".join([
      "torchscript-module-to-torch-backend-pipeline",
      "torch-backend-to-linalg-on-tensors-backend-pipeline"
  ])

  TYPE_REGEX = re.compile("\[(.+)\],\W*(.+),\W*(.+)")

  @classmethod
  def parse_type(cls, string):
    parse_result = cls.TYPE_REGEX.match(string)
    if parse_result is None:
      raise TypeError(f"Unable to parse type annotation: {string}")
    groups = parse_result.groups()

    shape = list(map(int, groups[0].split(",")))

    try:
      import torch
    except ModuleNotFoundError:
      raise RuntimeError("Please install torch to use dynamic-torch mode")
    dtype = torch.__dict__[groups[1]]

    has_value_semantics = groups[2].lower() == "true"

    return (shape, dtype, has_value_semantics)

  def create_subparser(self, subparser):
    pretty_name = self.name.split("-")[0].capitalize()
    parser = subparser.add_parser(
        self.name, help=f'{pretty_name} mode (from Torch through torch-mlir)')

    parser.add_argument("--method",
                        required=True,
                        help="Kernel method to compile")

    parser.add_argument(
        "--types",
        required=True,
        nargs="+",
        type=self.parse_type,
        help="Input types for the kernel, specified as torch-mlir annotations")

    return parser

  def run_torch_mlir(self):
    # Run torch-mlir and opts to generate affine level MLIR.
    try:
      import torch.jit
      from torch_mlir.dialects.torch.importer.jit_ir import (ClassAnnotator,
                                                             ModuleBuilder)
      from torch_mlir.passmanager import PassManager
    except ModuleNotFoundError:
      print_error("Please install torch_mlir to use dynamic-torch mode")

    import importlib.util
    import sys

    # Import the Python kernel file.
    kernel_file = args.kernel_file
    kernel_name = args.kernel_name
    spec = importlib.util.spec_from_file_location(kernel_name, kernel_file)
    module = importlib.util.module_from_spec(spec)
    sys.modules[kernel_name] = module
    spec.loader.exec_module(module)

    # Instantiate the kernel torch.nn.Module and run it through the Torch JIT.
    program = module.__dict__[kernel_name]()
    mb = ModuleBuilder()
    scripted = torch.jit.script(program)
    class_annotator = ClassAnnotator()

    # Import and compile the module with torch-mlir.
    types = [None] + args.types
    class_annotator.exportNone(scripted._c._type())
    class_annotator.exportPath(scripted._c._type(), [args.method])
    class_annotator.annotateArgs(scripted._c._type(), [args.method], types)

    mb.import_module(scripted._c, class_annotator)
    with mb.module.context:
      pm = PassManager.parse(self.PASSES)
      pm.run(mb.module)

    # Output the MLIR at the level of the torch-mlir backend contract.
    torch_mlir_outfile = self.genPrefixedOutputFileName("torch_mlir.mlir")
    with open(torch_mlir_outfile, 'w') as f:
      print(mb.module, file=f)

    # Lower from linalg on tensors to affine loops.
    affine_initial_outfile = self.genPrefixedOutputFileName(
        "affine_initial.mlir")
    runIfNotExists(
        affine_initial_outfile, lambda: run_mlir_opt([
            "--linalg-comprehensive-module-bufferize=\"allow-return-memref use-alloca\"",
            "--convert-linalg-to-affine-loops"
        ], torch_mlir_outfile, affine_initial_outfile))

    # Detect reduction loops to turn memrefs into iter args.
    affine_opt1_outfile = self.genPrefixedOutputFileName("affine_opt1.mlir")
    runIfNotExists(
        affine_opt1_outfile, lambda: run_polygeist_opt([
            "--detect-reduction",
        ], affine_initial_outfile, affine_opt1_outfile))

    # Replace memrefs with scalars.
    affine_opt2_outfile = self.genPrefixedOutputFileName("affine_opt2.mlir")
    runIfNotExists(
        affine_opt2_outfile, lambda: run_mlir_opt(
            ["--affine-scalrep"], affine_opt1_outfile, affine_opt2_outfile))

    runIfNotExists(
        self.kernel_affine, lambda: run_hls_opt(
            ["--affine-scalrep"], affine_opt2_outfile, self.kernel_affine))

    # The top level is now the torch.nn.Module method.
    args.kernel_name = args.method


class TorchDynamicMode(TorchMode, DynamicMode):

  def __init__(self):
    super().__init__('dynamic-torch')

  def run_lowering(self):
    if not args.mlir_kernel:
      self.run_torch_mlir()
      print_info(f"Lowered to affine! (Torch)...! ({self.kernel_affine})")
    else:
      print_info("Skipping Torch lowering due to using an MLIR kernel")
      copyAllowSame(args.kernel_file, self.kernel_affine)

    # Transition to handshake lowering
    super().run_lowering()


class TorchStaticMode(TorchMode, StaticMode):

  def __init__(self):
    super().__init__('static-torch')

  def run_lowering(self):
    if not args.mlir_kernel:
      self.run_torch_mlir()
      print_info(f"Lowered to affine! (Torch)...! ({self.kernel_affine})")
    else:
      print_info("Skipping Torch lowering due to using an MLIR kernel")
      copyAllowSame(args.kernel_file, self.kernel_affine)

    # Transition to Calyx lowering
    super().run_lowering()


class PolygeistStaticMode(PolygeistMode, StaticMode):

  def __init__(self):
    super().__init__('static-polygeist')

  def create_subparser(self, subparser):
    parser = subparser.add_parser(self.name,
                                  help='Static mode (from C through Polygeist)')
    parser.add_argument("--method",
                        required=True,
                        help="Kernel method to compile")
    return parser

  def run_lowering(self):
    if not args.mlir_kernel:
      self.run_polygeist()
      print_info(f"Lowered to affine! (Torch)...! ({self.kernel_affine})")
    else:
      print_info("Skipping Polygeist lowering due to using an MLIR kernel")
      copyAllowSame(args.kernel_file, self.kernel_affine)

    # Transition to Calyx lowering
    super().run_lowering()


# Handles for the global 'Mode' objects
polygeistDynMode = PolygeistDynamicMode()
polygeistStaticMode = PolygeistStaticMode()
torchStaticMode = TorchStaticMode()
torchDynamicMode = TorchDynamicMode()

HLSModes = [
    polygeistDynMode, torchDynamicMode, torchStaticMode, polygeistStaticMode
]


# Loads a checkpoint file in the current directory
def load_checkpoint(args):
  if os.path.exists(".hlstool_checkpoint"):
    with open(".hlstool_checkpoint", "r") as f:
      checkpoint_args = json.load(f)
      # overwrite args with checkpoint args
      for key, value in checkpoint_args.items():
        vars(args)[key] = value
    print_info("Using input files from .hlstool_checkpoint")
    return True
  return False


def store_checkpoint(args):
  checkpoint_args = {}
  argsDict = vars(args)

  def addIfExists(key):
    if key in argsDict and argsDict[key] != None:
      checkpoint_args[key] = argsDict[key]

  with open(".hlstool_checkpoint", "w") as f:
    addIfExists("tb_file")
    addIfExists("kernel_file")
    addIfExists("kernel_name")

    f.write(json.dumps(checkpoint_args, indent=2, sort_keys=True))
  print_info(
      "Stored checkpoint to .hlstool_checkpoint. You can rerun HLSTool "
      "in this directory and pass the --checkpoint flag instead of providing "
      "paths and kernel names.")


def parse_args(parser):
  global mode
  global args
  args = parser.parse_args()
  print_header("Parsing and validating arguments")

  # First we validate the general arguments.
  if not args.tb_file and not args.kernel_file and not args.kernel_name:
    if not load_checkpoint(args):
      parser.error(
          "Must specify either testbench name (to infer kernel and kernel name)"
          " or kernel file and kernel name.")
  if args.tb_file and not args.kernel_file and not args.kernel_name:
    # Infer kernel file and name from testbench
    print_info("Inferring kernel file and name from testbench name.")
    dirname = os.path.dirname(args.tb_file)
    basename = os.path.basename(args.tb_file)
    basename = os.path.splitext(basename)[0]

    if not basename.startswith("tst_"):
      parser.error("Testbench name must start with 'tst_' in inference mode")
      sys.exit(1)

    basename = basename[4:]

    ext = ".c"
    if args.mlir_kernel:
      ext = ".mlir"
    args.kernel_file = os.path.join(dirname, basename + ext)
    args.kernel_name = basename

  # Ensure provided files are absolute paths
  if args.tb_file:
    args.tb_file = os.path.abspath(args.tb_file)
  args.kernel_file = os.path.abspath(args.kernel_file)

  # End of inference; kernel name and kernel file must have been fully specified
  if not args.kernel_file:
    parser.error("Must specify kernel file (--kernel_file")

  if not args.kernel_name:
    parser.error("Must specify kernel name (--kernel_name)")

  print_info("using kernel file: {}".format(args.kernel_file))
  print_info("using kernel name: {}".format(args.kernel_name))
  print_info("using testbench file: {}".format(args.tb_file))

  # Store checkpoint
  store_checkpoint(args)

  # Validate extra polygeist args
  if args.extra_polygeist_tb_args == None:
    args.extra_polygeist_tb_args = []
  else:
    args.extra_polygeist_tb_args = args.extra_polygeist_tb_args.split(" ")

  if args.extra_polygeist_kernel_args == None:
    args.extra_polygeist_kernel_args = []
  else:
    args.extra_polygeist_kernel_args = args.extra_polygeist_kernel_args.split(
        " ")

  # Set current mode
  mode = None
  for it in HLSModes:
    if args.mode == it.name:
      mode = it
      break

  if not mode:
    parser.print_help()
    sys.exit(1)

  # Parse mode arguments
  print_step(f"Parsing '{mode.name}' mode arguments")
  mode.parse_arguments(parser)
  print_info("Arguments parsed and validated successfully!")


# An entry point
if __name__ == '__main__':
  # and argparser taking a mandatory argument "mode"
  parser = argparse.ArgumentParser(
      description="""
HLSTool is a tool for driving an end-to-end MLIR based HLS flow.


Usage:
Arguments are provided at two levels. First, generic arguments are specified, which
applies to any mode. The second level are mode specific arguments.
Generic arguments are specified before the (positional) mode argument.
To see the arguments for a specific mode, use\n
   'hlstool {mode} --help'
""",
      formatter_class=argparse.RawTextHelpFormatter)

  # A sub parser for the "dynamic" mode
  subparsers = parser.add_subparsers(help='Mode options', dest='mode')

  # General arguments
  parser.add_argument('--silent',
                      action='store_true',
                      help='Silent mode; suppress all output.',
                      default=False)

  parser.add_argument('--kernel_file',
                      type=str,
                      help='Path to the file containing the kernel.',
                      required=False)

  parser.add_argument(
      '--tb_file',
      type=str,
      help='Testbench file. If only this is specified, the kernel '
      'name and kernel file are inferred from the testbench name. '
      'When inferring this, testbenches are expected to be named \'tst_${kernel_name}.c\'.',
      required=False)

  parser.add_argument(
      '--tb_entry',
      type=str,
      help=
      'Testbench entry point. If not specified, the default entry point is used.',
      required=False,
      default='main')

  parser.add_argument(
      '--kernel_name',
      type=str,
      help='The kernel name is the name of the function within the '
      'kernel file which is to be compiled.',
      required=False)

  parser.add_argument('--outdir',
                      type=str,
                      help='Output directory. If not specified, '
                      'the output directory is the current working directory.',
                      required=False,
                      default=os.getcwd())

  parser.add_argument("--vcd",
                      type=str,
                      help="Path to a VCD file generated by the testbench.",
                      required=False)

  parser.add_argument("--no_trace",
                      action='store_true',
                      help="Disable tracing during simulation.",
                      required=False)
  parser.add_argument(
      "--vlt_threads",
      type=int,
      help="Number of Verilator threads to use. Defaults to the "
      "number of available threads / 2.",
      required=False,
      default=multiprocessing.cpu_count() // 2)

  parser.add_argument(
      "--rebuild",
      action='store_true',
      help="Always rebuild any output file of the tool. If this is not set, "
      "steps will be skipped when an expected output file already exists.",
      default=False)

  parser.add_argument(
      "--synth",
      action='store_true',
      help="Run Vivado and generate a resource estimate. An output text file "
      "will be generated in the output directory.")

  parser.add_argument(
      "--cosim",
      action='store_true',
      help="Modify and run the testbench in cosim mode. This requires that a "
      "software version of the kernel is available (standard MLIR).")

  parser.add_argument(
      "--checkpoint",
      action='store_true',
      help="Run HLSTool using a checkpoint file in the current directory. Each "
      "time HLSTool is executed, it will store a checkpoint file in the working "
      "directory which can be used to quickly reference the testbench and kernel "
      "files that was passed to HLSTool.")

  parser.add_argument(
      "--mlir_kernel",
      action='store_true',
      help="If set, the kernel is assumed to be an MLIR kernel. This will skip "
      "the Polygeist step. Kernel name inference via. testbench name still works, "
      "however, kernel file is expected to be suffixed with '.mlir'.")

  parser.add_argument(
      "--extra_polygeist_tb_args",
      type=str,
      help=
      "Extra arguments to pass to Polygeist during testbench lowering. Expects "
      "a space-delimited string.",
      required=False)

  parser.add_argument(
      "--extra_polygeist_kernel_args",
      type=str,
      help="Extra arguments to pass to Polygeist during kernel lowering. Expects "
      "a space-delimited string.",
      required=False)
  # Add mode arguments
  polygeistDynMode.add_arguments(polygeistDynMode.create_subparser(subparsers))
  polygeistStaticMode.add_arguments(
      polygeistStaticMode.create_subparser(subparsers))
  torchDynamicMode.add_arguments(torchDynamicMode.create_subparser(subparsers))
  torchStaticMode.add_arguments(torchStaticMode.create_subparser(subparsers))

  # Parse arguments
  parse_args(parser)

  # Move to the output directory
  os.chdir(args.outdir)
  print_info("Working directory is now {}".format(args.outdir))
  fileGraph = FileGraph(args.outdir)

  # Run the current mode
  print_header(f"Running '{mode.name}' mode")
  mode.run()
